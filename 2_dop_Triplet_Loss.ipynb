{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kovzanok/dls-final-task/blob/main/2_dop_Triplet_Loss.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Triplet Loss"
      ],
      "metadata": {
        "id": "IhSLtrD2R2Ok"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Triplet Loss — это один из лоссов для contrastive learning. Чтобы учить модель с помощью этого лосса, модели не нужен последний классификационный слой. Этот лосс работает прямо с эмбеддингами $x_i$ элементов, которые выдает модель."
      ],
      "metadata": {
        "id": "kPy1LODHR6JC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Снова скажем, что идея лосса — заставить эмбеддинги лиц одного человека быть более близкими по некоторому расстоянию, а эмбеддинги лиц разных людей — далекими друг от друга. Общая формула лосса выглядит так:\n",
        "\n",
        "$$L(e, p, n) = max\\{d(a, p) - d(a, n) + margin, 0\\},$$\n",
        "\n",
        "здесь\n",
        "- $e$ — эмбеддинг входного лица (output модели)\n",
        "- $p$ — \"positive\" эмбеддинг для входного лица (т.е. эмбеддинг такого элемента, что мы хотим, чтобы $e$ и $p$ были близки. В нашем случае это значит, что $e$ и $p$ должны быть выходами сети на два разных фото одного и того же человека).\n",
        "- $n$ — \"negative\" эмбеддинг для входного лица (т.е. эмбеддинг такого элемента, что мы хотим, чтобы $e$ и $p$ были далеки. В нашем случае это значит, что $e$ и $p$ должны быть выходами сети на два разных фото разных людей).\n",
        "- $d(x, y)$ — метрика расстояния между эмбеддингами, по которой мы их сравниваем.\n",
        "- margin — гиперпараметр, который заставляет $d(a, p)$ и $d(a, n)$ быть еще дальше друг от друга.\n",
        "\n",
        "**Эмбеддинги $e$, $p$ и $n$ нужно нормализовать, прежде чем подавать в лосс-функцию**.\n",
        "\n",
        "У TripletLoss есть куча разных вариаций. В некоторых из них больше гиперпараметров, в других предлагают использовать больше одного позитивного и негативного эмбеддинга за раз. Где-то предлагается умный способ выбора negative эмбеддинга (например, выбирается такой, на котором нейросеть пока плохо работает, т.е. считает $e$ и $n$ близкими).\n",
        "\n",
        "Пример реализации TripletLoss можно найти [здесь](https://pytorch.org/docs/stable/generated/torch.nn.TripletMarginWithDistanceLoss.html#torch.nn.TripletMarginWithDistanceLoss).\n",
        "\n",
        "Будьте готовы, что TripletLoss придется настраивать, чтобы добиться хорошего результата при обучении сети.\n"
      ],
      "metadata": {
        "id": "6cMS9QhvTE2q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Что нужно учесть при реализации Triplet Loss**:\n",
        "- при обучении мы обычно хотим следить за ходом обучения модели, считая какую-то метрику качества. Тут у нас больше нет классификационного слоя, так что accuracy мы считать не можем. Нужно придумать, как в случае Triplet Loss считать метрику качества на вализации в течение обучения. Подумайте, как можно это сделать?\n",
        "- скорее всего, чтобы обучить сеть на Triplet Loss, придется написать кастомный Dalaset/Dataloader, который будет возвращать тройки элементов (anchor, positive, negative).\n",
        "- не забудьте нормализовать эмбеддинги перед подсчетом лосса! Это можно сделать руками, а можно, например, добавить в конец сети batchnorm без обучаемых параметров."
      ],
      "metadata": {
        "id": "XYTA2a28Vwvk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Доп литература по Triplet Loss**:\n",
        "\n",
        "- Идея TripletLoss: https://en.wikipedia.org/wiki/Triplet_loss\n",
        "- Хорошая статья про batch mining techniques для выбора positive и negative элементов: https://omoindrot.github.io/triplet-loss#triplet-mining\n"
      ],
      "metadata": {
        "id": "sDtNoSCpVbKF"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JknUpnIvvtFA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
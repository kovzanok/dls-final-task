{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kovzanok/dls-final-task/blob/main/1_FaceAlignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Face Alignment"
      ],
      "metadata": {
        "id": "KzqOrj12f0xj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Архитектура Stacked Hourglass Network"
      ],
      "metadata": {
        "id": "EL-A4pxCgFW3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hourglass** — это U-Net-подобная структура, которая сначала уменьшает разрешение изображения, затем восстанавливает его обратно. Такая структура напоминает по форме песочные часы (hourglass).\n",
        "\n",
        "**Stacked Hourglass Network** состоит Hourglass-блоков, каждый из которых старается уточнять результат предыдущего. Несмотря на то, что она придумана в 2016 году, до сих пор используется во многих исследовательских проектах для задачи обнаружения ключевых точек."
      ],
      "metadata": {
        "id": "qCcIzaPKQUXX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image](https://production-media.paperswithcode.com/methods/Screen_Shot_2020-06-23_at_12.49.50_PM.png)"
      ],
      "metadata": {
        "id": "VnMxe71DfOQC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hourglass module"
      ],
      "metadata": {
        "id": "ORfrDj7604y7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Посмотрим подробнее на структуру **отдельного Hourglass-блока**"
      ],
      "metadata": {
        "id": "1BkzHwNcgjwD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![retrt](https://production-media.paperswithcode.com/methods/Screen_Shot_2020-06-23_at_12.50.12_PM.png)"
      ],
      "metadata": {
        "id": "GC8ctpVSjx8f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Каждый бокс в этой схеме - это Residual block, который отвечает за извлечение признаков на разных уровнях детализации (вспоминаем про ResNet). Причем, каждый такой блок иммеет одинаковую размерность на входе и на выходе.\n",
        "\n",
        "Downsampling и upsampling можно делать разными способами.\n",
        "\n",
        "*   Для Downsampling: nn.MaxPool2d или nn.Conv2d\n",
        "*   Для Upsampling: nn.Upsample или nn.ConvTranspose2d\n",
        "\n",
        "Основная разница: maxpool и upsample - необучаемые слои в отличие от сверток. Это может как быть как минусом, так и плюсом: чем больше параметров - тем медленее идет процесс обучения (при этом не факт, что результаты будут лучше).\n",
        "\n",
        "То есть, идейно все практически также как было в U-net: полностью симметричная архитектура, сначала идет преобразование в более низкоразмерное пространство, а потом декодирование обратно с пробросами результатов из соотвествующих слоев энкодера. Разница лишь в том, что теперь каждый кирпичик - это Residual block."
      ],
      "metadata": {
        "id": "pFfgyC02xW1r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "А вот реализация ResidualBlock вам в помощь!\n",
        "\n",
        "Но можете ее править под себя, если очень хочется."
      ],
      "metadata": {
        "id": "KTujcry6RvrR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "При построении архитектуры Hourglass-блоков **не обязательно полностью повторять архитектуру**, которая представлена на картинке из статьи. Вы можете добавлять больше или меньше модулей, некоторые блоки вообще можно не использовать. В целом, это творческая задача и вы вольны делать так, как вам самим хочется. **Главное - чтобы ваша реализация соотвествовала изначальной идее Hourglass, и итоговые результаты были достаточно хорошими.**"
      ],
      "metadata": {
        "id": "E5VgRrp7dhHh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Stacked Hourglass Network"
      ],
      "metadata": {
        "id": "l53fOmfs4i_j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Как и было сказано ранее, Stacked Hourglass - это набор одинаковых Hourglass блоков (см. схематический рисунок в начале ноутбука). Но что это за блок между каждыми двумя Hourglass? Чтобы ответить на этот вопрос, нужно сначала разобраться с тем, что мы будем получать на выходе такой нейронной сети.\n",
        "\n",
        "Предсказывать ключевые точки лица можно поразному. Есть два основных подхода:\n",
        "\n",
        "1.   Регрессия - предсказывает координаты точек лица напрямую -> $(N, x, y)$.\n",
        "2.   Heatmap - предсказывает карту вероятностей на выходе, а наиболее подходящие точки находятся через argmax\n",
        "\n",
        "Не вдваясь в подробности, можно просто сказать, что Heatmap-подход показал себя лучше из-за своей устойчивости к шумам и начальным условиям. В качестве функции потерь в таком случае используют обычный **MSE loss**.\n",
        "\n",
        "В Stacked Hourglass **используется именно heatmap-подход**. И на выходе каждого Hourglass-блока находится слой (голова), который создает heatmap нужного размера. Обычно это какие-то стандартные варианты по типу *Conv -> BatchNorm -> Relu -> Conv* или просто *Conv*. Каждая heatmap'a прокидывается на следующую голову, и они суммируются, и так, пока слои не закончатся.\n",
        "\n",
        "Такой подход нужен для реализации **Intermediate Supervision**. Если говорить простыми словами, то это такой вариант обучения нейронной сети, когда мы подсчитываем лосс не только по финальному выходу сети, а также на некоторых промежуточных слоях (головах). Градиенты в этом случае тоже распространяются не только через последний выход, но и через промежуточные уровни. Эти головы не влияют на финальное предсказание напрямую, но помогают модели быстрее и лучше учиться. На практике это означет следующее:\n",
        "\n",
        "Нужно посчитать лосс (таргет для всех одинаковый) для каждой головы отдельно, а потом просуммировать. Далее Pytorch сам построит за вас весь граф вычислений и правильно запустит везде градиенты. В коде это выглядит так:\n",
        "\n",
        "```\n",
        "outputs = model(image)  # outputs — список из N heatmaps от разных голов\n",
        "losses = [loss_function(output, target) for output in outputs]\n",
        "total_loss = sum(losses)\n",
        "total_loss.backward()\n",
        "optimizer.step()\n",
        "```\n",
        "\n",
        "Подведем **итоги по архитектуре**.\n",
        "\n",
        "Stacked Hourglass состоит из Hourglass-блоков, после каждого такого блока идет голова, которая предсказывает heatmap'у. Каждая heatmap'а суммируется с предыдущей. Градиенты при обучении текут с каждой головы, а не только через последний выход сети.\n",
        "\n",
        "Подробно про Stacked Hourglass Network можно прочитать в [оригинальной статье](https://arxiv.org/pdf/1603.06937)."
      ],
      "metadata": {
        "id": "g-eXEnTZ4lzw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Датасет"
      ],
      "metadata": {
        "id": "awt70vT4INrJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Есть множество датасетов для этой задачи, но для наших целей должно хватить и [CelebA](https://www.kaggle.com/datasets/jessicali9530/celeba-dataset). К сожалению или к счастью в разметке там всего 5 точек\n",
        "\n",
        "1.   Левый глаз\n",
        "2.   Правый глаз\n",
        "3.   Нос\n",
        "4.   Левый уголок рта\n",
        "5.   Правый уголок рта\n",
        "\n",
        "\n",
        "Единственная проблема заключается в том, что разметка - это именно точки, а не heatmap'ы. Но можно их сгенерировать самостоятельно при помощи гауссовского распределения вокруг размеченных точек. Вот вам функции в помощь. Можете их тоже редактивовать под себя, если нужно."
      ],
      "metadata": {
        "id": "W44IH6v6IQqq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Сам по себе CelebA избыточно большой для нашей задачи, поэтому можете использовать только его часть. Также, имеет смысл заранее кропнуть картинки таким образом, чтобы на них остались только лица, ну или по крайней мере минимум всего остального."
      ],
      "metadata": {
        "id": "CB4tkC6shLYB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Выравнивание по предсказанным точкам"
      ],
      "metadata": {
        "id": "3j9aXyK4R874"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Существует множество вариантов, как по полученным точкам правильно преобразовать картинку. Главное, что вам нужно понимать - **это задача классического компьютерного зрения** и решается при помощи математики, без нейронок. Вдаваться в подробности конкретных алгоритмов мы не будем.\n",
        "\n",
        "Можно использовать аффинное преобразование, тогда потребуется только 3 точки, можно, например, искать матрицу гомографии, где может быть использовано больше точек, а может быть, есть еще что-то. Реализовывать эти алгоритмы самим не нужно. Достаточно провести небольшой ресерч и найти готовое решение (но **не готовую нейронку для выравнивания**), лишь бы оно работало. Количество используемых точек тоже выбирайте сами, подойдет любой вариант. Условный ориентир для поиска - библиотека **opencv**."
      ],
      "metadata": {
        "id": "jms68U10SCvF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# План заданий"
      ],
      "metadata": {
        "id": "_g1vDgOpU1Gh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "По итогу, в этом блоке у вас следующие задачи:\n",
        "\n",
        "\n",
        "*   Реализовать Hourglass блок\n",
        "*   Реализовать Stacked Hourglass\n",
        "*   Подготовить датасет, преобразовав точки в Heatmap'ы\n",
        "*   Обучить модель\n",
        "*   Найти или реализовать функцию, которая бы по предсказанным ключевым точкам делала бы выравнивание лица на картинке (face alignment)\n",
        "\n",
        "**P.S. Не забывайте сохранять модели после обучения и выводите промежуточные результаты на экран**\n",
        "\n"
      ],
      "metadata": {
        "id": "7iLkHjkoU_ep"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def create_heatmap(size, landmark, sigma=2):\n",
        "    \"\"\"\n",
        "    Создаёт один heatmap с гауссовым ядром вокруг точки.\n",
        "\n",
        "    :param size: (height, width) — размер heatmap'а\n",
        "    :param landmark:(x, y) — координаты точки\n",
        "    :param sigma\n",
        "    :return: heatmap массив\n",
        "    \"\"\"\n",
        "    x, y = landmark\n",
        "    h, w = size\n",
        "\n",
        "    # Обрезаем координаты, чтобы не выйти за пределы изображения\n",
        "    x = min(max(0, int(x)), w - 1)\n",
        "    y = min(max(0, int(y)), h - 1)\n",
        "\n",
        "    xx, yy = np.meshgrid(np.arange(w), np.arange(h))\n",
        "    heatmap = np.exp(-((yy - y)**2 + (xx - x)**2) / (2 * sigma**2))\n",
        "    return heatmap\n",
        "\n",
        "\n",
        "def landmarks_to_heatmaps(image_shape, landmarks, sigma=2):\n",
        "    \"\"\"\n",
        "    Преобразует список из N точек в набор из N heatmap'ов.\n",
        "\n",
        "    :param image_shape: исходный размер изображения (H, W)\n",
        "    :param landmarks: список из N пар координат [(x1, y1), (x2, y2), ..., (xN, yN),]\n",
        "    :param sigma:\n",
        "    :return: массив heatmap'ов вида [N, H, W]\n",
        "    \"\"\"\n",
        "    heatmaps = []\n",
        "\n",
        "    for landmark in landmarks:\n",
        "        hm = create_heatmap(image_shape, landmark, sigma=sigma)\n",
        "        heatmaps.append(hm)\n",
        "\n",
        "    return np.array(heatmaps)"
      ],
      "metadata": {
        "id": "VAZC55CnIPlU"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Удачи! У вас всё получится 💗!**"
      ],
      "metadata": {
        "id": "EFoJGPw2Vkxb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DG4RhSxaTWcs",
        "outputId": "40535e84-a8d3-4817-e7dc-b21552ae8c29"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q /content/drive/MyDrive/img_align_celeba.zip -d /content/celeba/"
      ],
      "metadata": {
        "id": "qiyy_AgDTo0F"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "from torchvision.datasets import ImageFolder\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "eHNy9XnXgGHu"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/celeba/list_landmarks_align_celeba.csv', index_col=0)"
      ],
      "metadata": {
        "id": "7Rzc0KiIR7Vj"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def row_to_coords(row):\n",
        "    return row.to_numpy().reshape(-1, 2)\n",
        "# Добавим колонку с массивом координат:\n",
        "landmarks_df = df.head(200).apply(row_to_coords, axis=1)"
      ],
      "metadata": {
        "id": "1ZCAAESaTbnx"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "landmarks_array = landmarks_df.drop(columns=['image_name']).to_numpy().reshape(-1)"
      ],
      "metadata": {
        "id": "h0v4vdFSUhHN"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_heatmaps(heatmaps):\n",
        "    n = heatmaps.shape[0]\n",
        "    plt.figure(figsize=(15, 3))\n",
        "    for i in range(n):\n",
        "        plt.subplot(1, n, i+1)\n",
        "        plt.imshow(heatmaps[i], cmap='hot')\n",
        "        plt.title(f'Heatmap {i+1}')\n",
        "        plt.axis('off')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "iTm1BFQoY3bN"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for landmark in landmarks_array:\n",
        "    heat_maps = landmarks_to_heatmaps((218,178),landmark)\n",
        "    show_heatmaps(heat_maps)\n",
        "    break"
      ],
      "metadata": {
        "id": "b9F79RwpXIU4",
        "outputId": "8048d047-3db6-404c-d4d9-37dc4070ffc3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x300 with 5 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.skip = nn.Identity() if in_channels == out_channels else nn.Conv2d(in_channels, out_channels, 1)\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels // 2, 1)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels // 2)\n",
        "        self.conv2 = nn.Conv2d(out_channels // 2, out_channels // 2, 3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels // 2)\n",
        "        self.conv3 = nn.Conv2d(out_channels // 2, out_channels, 1)\n",
        "        self.bn3 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = self.skip(x)\n",
        "        x = self.relu(self.bn1(self.conv1(x)))\n",
        "        x = self.relu(self.bn2(self.conv2(x)))\n",
        "        x = self.bn3(self.conv3(x))\n",
        "        return self.relu(x + residual)"
      ],
      "metadata": {
        "id": "Jv_DRIP0Rqhb"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class HourglassBlock(nn.Module):\n",
        "    def __init__(self, channels):\n",
        "        super().__init__()\n",
        "        self.res1 = ResidualBlock(channels, channels)\n",
        "        self.res2 =  ResidualBlock(channels, channels)\n",
        "        self.res_center =  ResidualBlock(channels, channels)\n",
        "        self.res3 =  ResidualBlock(channels, channels)\n",
        "        self.res4 =  ResidualBlock(channels, channels)\n",
        "\n",
        "        self.downsample = nn.MaxPool2d(kernel_size=2,stride=2)\n",
        "        self.upsample = nn.Upsample(scale_factor=2,mode='nearest')\n",
        "\n",
        "    def forward(self, x):\n",
        "        skip1 = self.res1(x)\n",
        "        x = self.downsample(skip1)\n",
        "        skip2 = self.res2(x)\n",
        "        x = self.downsample(skip2)\n",
        "        x = self.res_center(x)\n",
        "        x = self.upsample(x)\n",
        "        x = self.res3(x)+skip2\n",
        "        x = self.upsample(x)\n",
        "        x = self.res4(x)+skip1\n",
        "        return x"
      ],
      "metadata": {
        "id": "uwcRn4U9CNdd"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class HourglassNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.initial_conv = nn.Conv2d(3, 64, kernel_size=7, stride=1, padding=3)\n",
        "        self.bn = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "        self.hg1 = HourglassBlock(64)\n",
        "        self.hg2 = HourglassBlock(64)\n",
        "        self.hg3 = HourglassBlock(64)\n",
        "\n",
        "        self.head1 = nn.Conv2d(64, 5)\n",
        "        self.head2 = nn.Conv2d(64, 5)\n",
        "        self.head3 = nn.Conv2d(64, 5)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.initial_conv(x)\n",
        "        x = self.relu(self.bn(x))\n",
        "        skip1 = self.hg1(x)\n",
        "        res1 = self.head1(skip1)\n",
        "        skip2 = self.hg2(skip1)+skip1\n",
        "        res2 = self.head2(skip2)\n",
        "        x = self.hg3(skip2)+skip2\n",
        "        res3 = self.head3(x)\n",
        "        return [res1, res2, res3]\n",
        "\n"
      ],
      "metadata": {
        "id": "VblYJ_BhDQPV"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = ImageFolder(root='/content/celeba/img/img_align_celeba')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "xfMrFHYfWTU_",
        "outputId": "82b5d861-5a77-4b70-ab7d-8ff010471f67"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "Couldn't find any class folder in /content/celeba/img/img_align_celeba.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-5d14182cdc55>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImageFolder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/content/celeba/img/img_align_celeba'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, transform, target_transform, loader, is_valid_file, allow_empty)\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0mallow_empty\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m     ):\n\u001b[0;32m--> 328\u001b[0;31m         super().__init__(\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, loader, extensions, transform, target_transform, is_valid_file, allow_empty)\u001b[0m\n\u001b[1;32m    147\u001b[0m     ) -> None:\n\u001b[1;32m    148\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_transform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m         samples = self.make_dataset(\n\u001b[1;32m    151\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mfind_classes\u001b[0;34m(self, directory)\u001b[0m\n\u001b[1;32m    232\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m \u001b[0mof\u001b[0m \u001b[0mall\u001b[0m \u001b[0mclasses\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdictionary\u001b[0m \u001b[0mmapping\u001b[0m \u001b[0meach\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mto\u001b[0m \u001b[0man\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \"\"\"\n\u001b[0;32m--> 234\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfind_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mfind_classes\u001b[0;34m(directory)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mentry\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscandir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Couldn't find any class folder in {directory}.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mclass_to_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mcls_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: Couldn't find any class folder in /content/celeba/img/img_align_celeba."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train():\n",
        "    pass\n"
      ],
      "metadata": {
        "id": "bnVBLZekTPMT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
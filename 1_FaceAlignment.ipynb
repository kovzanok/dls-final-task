{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kovzanok/dls-final-task/blob/main/1_FaceAlignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Face Alignment"
      ],
      "metadata": {
        "id": "KzqOrj12f0xj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Архитектура Stacked Hourglass Network"
      ],
      "metadata": {
        "id": "EL-A4pxCgFW3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hourglass** — это U-Net-подобная структура, которая сначала уменьшает разрешение изображения, затем восстанавливает его обратно. Такая структура напоминает по форме песочные часы (hourglass).\n",
        "\n",
        "**Stacked Hourglass Network** состоит Hourglass-блоков, каждый из которых старается уточнять результат предыдущего. Несмотря на то, что она придумана в 2016 году, до сих пор используется во многих исследовательских проектах для задачи обнаружения ключевых точек."
      ],
      "metadata": {
        "id": "qCcIzaPKQUXX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image](https://production-media.paperswithcode.com/methods/Screen_Shot_2020-06-23_at_12.49.50_PM.png)"
      ],
      "metadata": {
        "id": "VnMxe71DfOQC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hourglass module"
      ],
      "metadata": {
        "id": "ORfrDj7604y7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Посмотрим подробнее на структуру **отдельного Hourglass-блока**"
      ],
      "metadata": {
        "id": "1BkzHwNcgjwD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![retrt](https://production-media.paperswithcode.com/methods/Screen_Shot_2020-06-23_at_12.50.12_PM.png)"
      ],
      "metadata": {
        "id": "GC8ctpVSjx8f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Каждый бокс в этой схеме - это Residual block, который отвечает за извлечение признаков на разных уровнях детализации (вспоминаем про ResNet). Причем, каждый такой блок иммеет одинаковую размерность на входе и на выходе.\n",
        "\n",
        "Downsampling и upsampling можно делать разными способами.\n",
        "\n",
        "*   Для Downsampling: nn.MaxPool2d или nn.Conv2d\n",
        "*   Для Upsampling: nn.Upsample или nn.ConvTranspose2d\n",
        "\n",
        "Основная разница: maxpool и upsample - необучаемые слои в отличие от сверток. Это может как быть как минусом, так и плюсом: чем больше параметров - тем медленее идет процесс обучения (при этом не факт, что результаты будут лучше).\n",
        "\n",
        "То есть, идейно все практически также как было в U-net: полностью симметричная архитектура, сначала идет преобразование в более низкоразмерное пространство, а потом декодирование обратно с пробросами результатов из соотвествующих слоев энкодера. Разница лишь в том, что теперь каждый кирпичик - это Residual block."
      ],
      "metadata": {
        "id": "pFfgyC02xW1r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "А вот реализация ResidualBlock вам в помощь!\n",
        "\n",
        "Но можете ее править под себя, если очень хочется."
      ],
      "metadata": {
        "id": "KTujcry6RvrR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "При построении архитектуры Hourglass-блоков **не обязательно полностью повторять архитектуру**, которая представлена на картинке из статьи. Вы можете добавлять больше или меньше модулей, некоторые блоки вообще можно не использовать. В целом, это творческая задача и вы вольны делать так, как вам самим хочется. **Главное - чтобы ваша реализация соотвествовала изначальной идее Hourglass, и итоговые результаты были достаточно хорошими.**"
      ],
      "metadata": {
        "id": "E5VgRrp7dhHh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Stacked Hourglass Network"
      ],
      "metadata": {
        "id": "l53fOmfs4i_j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Как и было сказано ранее, Stacked Hourglass - это набор одинаковых Hourglass блоков (см. схематический рисунок в начале ноутбука). Но что это за блок между каждыми двумя Hourglass? Чтобы ответить на этот вопрос, нужно сначала разобраться с тем, что мы будем получать на выходе такой нейронной сети.\n",
        "\n",
        "Предсказывать ключевые точки лица можно поразному. Есть два основных подхода:\n",
        "\n",
        "1.   Регрессия - предсказывает координаты точек лица напрямую -> $(N, x, y)$.\n",
        "2.   Heatmap - предсказывает карту вероятностей на выходе, а наиболее подходящие точки находятся через argmax\n",
        "\n",
        "Не вдваясь в подробности, можно просто сказать, что Heatmap-подход показал себя лучше из-за своей устойчивости к шумам и начальным условиям. В качестве функции потерь в таком случае используют обычный **MSE loss**.\n",
        "\n",
        "В Stacked Hourglass **используется именно heatmap-подход**. И на выходе каждого Hourglass-блока находится слой (голова), который создает heatmap нужного размера. Обычно это какие-то стандартные варианты по типу *Conv -> BatchNorm -> Relu -> Conv* или просто *Conv*. Каждая heatmap'a прокидывается на следующую голову, и они суммируются, и так, пока слои не закончатся.\n",
        "\n",
        "Такой подход нужен для реализации **Intermediate Supervision**. Если говорить простыми словами, то это такой вариант обучения нейронной сети, когда мы подсчитываем лосс не только по финальному выходу сети, а также на некоторых промежуточных слоях (головах). Градиенты в этом случае тоже распространяются не только через последний выход, но и через промежуточные уровни. Эти головы не влияют на финальное предсказание напрямую, но помогают модели быстрее и лучше учиться. На практике это означет следующее:\n",
        "\n",
        "Нужно посчитать лосс (таргет для всех одинаковый) для каждой головы отдельно, а потом просуммировать. Далее Pytorch сам построит за вас весь граф вычислений и правильно запустит везде градиенты. В коде это выглядит так:\n",
        "\n",
        "```\n",
        "outputs = model(image)  # outputs — список из N heatmaps от разных голов\n",
        "losses = [loss_function(output, target) for output in outputs]\n",
        "total_loss = sum(losses)\n",
        "total_loss.backward()\n",
        "optimizer.step()\n",
        "```\n",
        "\n",
        "Подведем **итоги по архитектуре**.\n",
        "\n",
        "Stacked Hourglass состоит из Hourglass-блоков, после каждого такого блока идет голова, которая предсказывает heatmap'у. Каждая heatmap'а суммируется с предыдущей. Градиенты при обучении текут с каждой головы, а не только через последний выход сети.\n",
        "\n",
        "Подробно про Stacked Hourglass Network можно прочитать в [оригинальной статье](https://arxiv.org/pdf/1603.06937)."
      ],
      "metadata": {
        "id": "g-eXEnTZ4lzw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Датасет"
      ],
      "metadata": {
        "id": "awt70vT4INrJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Есть множество датасетов для этой задачи, но для наших целей должно хватить и [CelebA](https://www.kaggle.com/datasets/jessicali9530/celeba-dataset). К сожалению или к счастью в разметке там всего 5 точек\n",
        "\n",
        "1.   Левый глаз\n",
        "2.   Правый глаз\n",
        "3.   Нос\n",
        "4.   Левый уголок рта\n",
        "5.   Правый уголок рта\n",
        "\n",
        "\n",
        "Единственная проблема заключается в том, что разметка - это именно точки, а не heatmap'ы. Но можно их сгенерировать самостоятельно при помощи гауссовского распределения вокруг размеченных точек. Вот вам функции в помощь. Можете их тоже редактивовать под себя, если нужно."
      ],
      "metadata": {
        "id": "W44IH6v6IQqq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Сам по себе CelebA избыточно большой для нашей задачи, поэтому можете использовать только его часть. Также, имеет смысл заранее кропнуть картинки таким образом, чтобы на них остались только лица, ну или по крайней мере минимум всего остального."
      ],
      "metadata": {
        "id": "CB4tkC6shLYB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Выравнивание по предсказанным точкам"
      ],
      "metadata": {
        "id": "3j9aXyK4R874"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Существует множество вариантов, как по полученным точкам правильно преобразовать картинку. Главное, что вам нужно понимать - **это задача классического компьютерного зрения** и решается при помощи математики, без нейронок. Вдаваться в подробности конкретных алгоритмов мы не будем.\n",
        "\n",
        "Можно использовать аффинное преобразование, тогда потребуется только 3 точки, можно, например, искать матрицу гомографии, где может быть использовано больше точек, а может быть, есть еще что-то. Реализовывать эти алгоритмы самим не нужно. Достаточно провести небольшой ресерч и найти готовое решение (но **не готовую нейронку для выравнивания**), лишь бы оно работало. Количество используемых точек тоже выбирайте сами, подойдет любой вариант. Условный ориентир для поиска - библиотека **opencv**."
      ],
      "metadata": {
        "id": "jms68U10SCvF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# План заданий"
      ],
      "metadata": {
        "id": "_g1vDgOpU1Gh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "По итогу, в этом блоке у вас следующие задачи:\n",
        "\n",
        "\n",
        "*   Реализовать Hourglass блок\n",
        "*   Реализовать Stacked Hourglass\n",
        "*   Подготовить датасет, преобразовав точки в Heatmap'ы\n",
        "*   Обучить модель\n",
        "*   Найти или реализовать функцию, которая бы по предсказанным ключевым точкам делала бы выравнивание лица на картинке (face alignment)\n",
        "\n",
        "**P.S. Не забывайте сохранять модели после обучения и выводите промежуточные результаты на экран**\n",
        "\n"
      ],
      "metadata": {
        "id": "7iLkHjkoU_ep"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Удачи! У вас всё получится 💗!**"
      ],
      "metadata": {
        "id": "EFoJGPw2Vkxb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Зависимости и загрузка данных"
      ],
      "metadata": {
        "id": "c3ucZ7mFjQsn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DG4RhSxaTWcs",
        "outputId": "f3c1e4f3-25bb-49b8-98c1-9206f915bc82"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q /content/drive/MyDrive/img_align_celeba.zip -d /content/celeba/"
      ],
      "metadata": {
        "id": "qiyy_AgDTo0F"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "from torch.optim import Adam\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "import random\n",
        "import os"
      ],
      "metadata": {
        "id": "eHNy9XnXgGHu"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "JXgqmonjkSxD"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "random.seed(42)"
      ],
      "metadata": {
        "id": "ycXe2lYulvWx"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Датасет"
      ],
      "metadata": {
        "id": "mOvimJkWjVuO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/list_landmarks_align_celeba.txt', index_col=0,delim_whitespace=True)"
      ],
      "metadata": {
        "id": "7Rzc0KiIR7Vj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4910190f-ef74-4e3f-d372-7c39cd399253"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-fca33805a727>:1: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
            "  df = pd.read_csv('/content/drive/MyDrive/list_landmarks_align_celeba.txt', index_col=0,delim_whitespace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.index.name = 'image_id'"
      ],
      "metadata": {
        "id": "adIEgOG0YaI0"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "taGKJGDZaxV-",
        "outputId": "8c6d7397-55db-438e-b688-2f89ebf135d6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            lefteye_x  lefteye_y  righteye_x  righteye_y  nose_x  nose_y  \\\n",
              "image_id                                                                   \n",
              "000001.jpg         69        109         106         113      77     142   \n",
              "000002.jpg         69        110         107         112      81     135   \n",
              "000003.jpg         76        112         104         106     108     128   \n",
              "000004.jpg         72        113         108         108     101     138   \n",
              "000005.jpg         66        114         112         112      86     119   \n",
              "\n",
              "            leftmouth_x  leftmouth_y  rightmouth_x  rightmouth_y  \n",
              "image_id                                                          \n",
              "000001.jpg           73          152           108           154  \n",
              "000002.jpg           70          151           108           153  \n",
              "000003.jpg           74          156            98           158  \n",
              "000004.jpg           71          155           101           151  \n",
              "000005.jpg           71          147           104           150  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6eaddfa0-ab82-4261-9cbc-cba66470a1be\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>lefteye_x</th>\n",
              "      <th>lefteye_y</th>\n",
              "      <th>righteye_x</th>\n",
              "      <th>righteye_y</th>\n",
              "      <th>nose_x</th>\n",
              "      <th>nose_y</th>\n",
              "      <th>leftmouth_x</th>\n",
              "      <th>leftmouth_y</th>\n",
              "      <th>rightmouth_x</th>\n",
              "      <th>rightmouth_y</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>image_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>000001.jpg</th>\n",
              "      <td>69</td>\n",
              "      <td>109</td>\n",
              "      <td>106</td>\n",
              "      <td>113</td>\n",
              "      <td>77</td>\n",
              "      <td>142</td>\n",
              "      <td>73</td>\n",
              "      <td>152</td>\n",
              "      <td>108</td>\n",
              "      <td>154</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>000002.jpg</th>\n",
              "      <td>69</td>\n",
              "      <td>110</td>\n",
              "      <td>107</td>\n",
              "      <td>112</td>\n",
              "      <td>81</td>\n",
              "      <td>135</td>\n",
              "      <td>70</td>\n",
              "      <td>151</td>\n",
              "      <td>108</td>\n",
              "      <td>153</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>000003.jpg</th>\n",
              "      <td>76</td>\n",
              "      <td>112</td>\n",
              "      <td>104</td>\n",
              "      <td>106</td>\n",
              "      <td>108</td>\n",
              "      <td>128</td>\n",
              "      <td>74</td>\n",
              "      <td>156</td>\n",
              "      <td>98</td>\n",
              "      <td>158</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>000004.jpg</th>\n",
              "      <td>72</td>\n",
              "      <td>113</td>\n",
              "      <td>108</td>\n",
              "      <td>108</td>\n",
              "      <td>101</td>\n",
              "      <td>138</td>\n",
              "      <td>71</td>\n",
              "      <td>155</td>\n",
              "      <td>101</td>\n",
              "      <td>151</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>000005.jpg</th>\n",
              "      <td>66</td>\n",
              "      <td>114</td>\n",
              "      <td>112</td>\n",
              "      <td>112</td>\n",
              "      <td>86</td>\n",
              "      <td>119</td>\n",
              "      <td>71</td>\n",
              "      <td>147</td>\n",
              "      <td>104</td>\n",
              "      <td>150</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6eaddfa0-ab82-4261-9cbc-cba66470a1be')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6eaddfa0-ab82-4261-9cbc-cba66470a1be button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6eaddfa0-ab82-4261-9cbc-cba66470a1be');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-b92db6d4-edf7-4034-9aad-7b352c088b10\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b92db6d4-edf7-4034-9aad-7b352c088b10')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-b92db6d4-edf7-4034-9aad-7b352c088b10 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keypoints_dict = {}\n",
        "\n",
        "for _, row in tqdm(df.iterrows()):\n",
        "    filename = row.name\n",
        "    keypoints = [(row.iloc[i], row.iloc[i+1]) for i in range(0, 9,2)]\n",
        "    keypoints_dict[filename] = keypoints\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ohNc8e5agHe",
        "outputId": "ef407f17-2bd0-4edd-b0e0-177a042a7969"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "202599it [00:19, 10211.70it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_heatmap(landmark, sigma=2):\n",
        "    \"\"\"\n",
        "    Создаёт один heatmap с гауссовым ядром вокруг точки.\n",
        "\n",
        "    :param size: (height, width) — размер heatmap'а\n",
        "    :param landmark:(x, y) — координаты точки\n",
        "    :param sigma\n",
        "    :return: heatmap массив\n",
        "    \"\"\"\n",
        "    x, y = landmark\n",
        "    h, w = (NEW_SIZE,NEW_SIZE)\n",
        "\n",
        "    # Обрезаем координаты, чтобы не выйти за пределы изображения\n",
        "    x = min(max(0, int(x)), w - 1)\n",
        "    y = min(max(0, int(y)), h - 1)\n",
        "\n",
        "    xx, yy = np.meshgrid(np.arange(w), np.arange(h))\n",
        "    heatmap = np.exp(-((yy - y)**2 + (xx - x)**2) / (2 * sigma**2))\n",
        "    return heatmap\n",
        "\n",
        "\n",
        "def landmarks_to_heatmaps(landmarks, sigma=2):\n",
        "    \"\"\"\n",
        "    Преобразует список из N точек в набор из N heatmap'ов.\n",
        "\n",
        "    :param image_shape: исходный размер изображения (H, W)\n",
        "    :param landmarks: список из N пар координат [(x1, y1), (x2, y2), ..., (xN, yN),]\n",
        "    :param sigma:\n",
        "    :return: массив heatmap'ов вида [N, H, W]\n",
        "    \"\"\"\n",
        "    heatmaps = []\n",
        "\n",
        "    for landmark in landmarks:\n",
        "        hm = create_heatmap(landmark, sigma=sigma)\n",
        "        heatmaps.append(hm)\n",
        "\n",
        "    return np.array(heatmaps)"
      ],
      "metadata": {
        "id": "VAZC55CnIPlU"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_heatmaps(heatmaps):\n",
        "    # heatmaps — numpy array с формой (5, H, W)\n",
        "    n = heatmaps.shape[0]\n",
        "    plt.figure(figsize=(15, 3))\n",
        "    for i in range(n):\n",
        "        plt.subplot(1, n, i+1)\n",
        "        plt.imshow(heatmaps[i], cmap='hot')\n",
        "        plt.title(f'Heatmap {i+1}')\n",
        "        plt.axis('off')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "mPaPMPl9Amh1"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ORIGINAL_W = 178\n",
        "ORIGINAL_H = 218\n",
        "NEW_SIZE = 128\n",
        "scale_x = NEW_SIZE / ORIGINAL_W\n",
        "scale_y = NEW_SIZE / ORIGINAL_H"
      ],
      "metadata": {
        "id": "Nw9fd8d_qQQq"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CelebADataset(Dataset):\n",
        "    def __init__(self, img_dir, keypoints_dict, transform=None, heatmap_generator=None):\n",
        "        super().__init__()\n",
        "        self.img_dir = img_dir\n",
        "        self.keypoints_dict = keypoints_dict  # словарь: {'000001.jpg': [(x1, y1), ..., (x5, y5)], ...}\n",
        "        self.transform = transform\n",
        "        self.heatmap_generator = heatmap_generator\n",
        "        self.image_names = list(keypoints_dict.keys())\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_names)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = self.image_names[idx]\n",
        "        img_path = os.path.join(self.img_dir, img_name)\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        keypoints = self.keypoints_dict[img_name]\n",
        "        scaled_keypoints = [(x * scale_x, y * scale_y) for (x, y) in keypoints]\n",
        "        heatmap = torch.tensor(self.heatmap_generator(scaled_keypoints)).float()\n",
        "\n",
        "        return image, heatmap\n"
      ],
      "metadata": {
        "id": "xfMrFHYfWTU_"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((NEW_SIZE, NEW_SIZE)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ColorJitter(brightness=0.1, contrast=0.1),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "dataset = CelebADataset(\n",
        "    img_dir='/content/celeba/img_align_celeba',\n",
        "    keypoints_dict=keypoints_dict,\n",
        "    transform=transform,\n",
        "    heatmap_generator=landmarks_to_heatmaps\n",
        ")"
      ],
      "metadata": {
        "id": "LKMMxMaAcYzM"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loader = DataLoader(dataset,batch_size=8)"
      ],
      "metadata": {
        "id": "ZBcvpXXgeLzy"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#HourglassNet"
      ],
      "metadata": {
        "id": "U3htbjsgjdgV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.skip = nn.Identity() if in_channels == out_channels else nn.Conv2d(in_channels, out_channels, 1)\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels // 2, 1)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels // 2)\n",
        "        self.conv2 = nn.Conv2d(out_channels // 2, out_channels // 2, 3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels // 2)\n",
        "        self.conv3 = nn.Conv2d(out_channels // 2, out_channels, 1)\n",
        "        self.bn3 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = self.skip(x)\n",
        "        x = self.relu(self.bn1(self.conv1(x)))\n",
        "        x = self.relu(self.bn2(self.conv2(x)))\n",
        "        x = self.bn3(self.conv3(x))\n",
        "        return self.relu(x + residual)"
      ],
      "metadata": {
        "id": "Jv_DRIP0Rqhb"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class HourglassBlock(nn.Module):\n",
        "    def __init__(self, channels, depth):\n",
        "        super().__init__()\n",
        "        self.depth = depth\n",
        "\n",
        "        self.res = ResidualBlock(channels, channels)\n",
        "\n",
        "        if depth > 1:\n",
        "            self.next = HourglassBlock(channels, depth - 1)\n",
        "        else:\n",
        "            self.center = ResidualBlock(channels, channels)\n",
        "\n",
        "\n",
        "        self.downsample = nn.MaxPool2d(kernel_size=2,stride=2)\n",
        "        self.upsample = nn.Upsample(scale_factor=2, mode='nearest')\n",
        "\n",
        "    def forward(self, x):\n",
        "        skip = self.res(x)\n",
        "        x = self.downsample(skip)\n",
        "\n",
        "        if self.depth > 1:\n",
        "            x = self.next(x)\n",
        "        else:\n",
        "            x = self.center(x)\n",
        "\n",
        "        x = self.upsample(x)\n",
        "        return x + skip"
      ],
      "metadata": {
        "id": "uwcRn4U9CNdd"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class HourglassNet(nn.Module):\n",
        "    def __init__(self, channels=128, depth=4):\n",
        "        super().__init__()\n",
        "        self.initial_conv = nn.Conv2d(3, channels, kernel_size=7, stride=1, padding=3)\n",
        "        self.bn = nn.BatchNorm2d(channels)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "        self.hg1 = HourglassBlock(channels,depth)\n",
        "        self.hg2 = HourglassBlock(channels,depth)\n",
        "        self.hg3 = HourglassBlock(channels,depth)\n",
        "\n",
        "        self.merge1 = nn.Conv2d(5, channels, kernel_size=1)\n",
        "        self.merge2 = nn.Conv2d(5, channels, kernel_size=1)\n",
        "\n",
        "        self.head1 = nn.Sequential(\n",
        "            nn.Conv2d(channels, 5, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(5)\n",
        "        )\n",
        "        self.head2 = nn.Sequential(\n",
        "            nn.Conv2d(channels, 5, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(5)\n",
        "        )\n",
        "        self.head3 = nn.Sequential(\n",
        "            nn.Conv2d(channels, 5, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(5)\n",
        "        )\n",
        "\n",
        "        self.conv1 = nn.Conv2d(channels, channels, 1)\n",
        "        self.conv2 = nn.Conv2d(channels, channels, 1)\n",
        "        self.conv3 = nn.Conv2d(channels, channels, 1)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.initial_conv(x)\n",
        "        x = self.relu(self.bn(x))\n",
        "        skip1 = self.hg1(x)\n",
        "        res1 = self.head1(self.conv1(skip1))\n",
        "        inter1 = skip1 + self.merge1(res1)\n",
        "        skip2 = self.hg2(inter1)\n",
        "        res2 = self.head2(self.conv2(skip2))\n",
        "        inter2 = skip2 + self.merge2(res2)\n",
        "        x = self.hg3(inter2)\n",
        "        res3 = self.head3(self.conv3(x))\n",
        "        return [res1, res2, res3]\n",
        "\n"
      ],
      "metadata": {
        "id": "VblYJ_BhDQPV"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Обучение"
      ],
      "metadata": {
        "id": "LjrptHsJjmJ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = HourglassNet().to(device)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = Adam(model.parameters())"
      ],
      "metadata": {
        "id": "Lo6EvjwWgOGM"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, criterion, optimizer, loader, epochs = 10):\n",
        "    model.train()\n",
        "    epoch_losses = []\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "        loss = train_epoch(model, criterion, optimizer, loader, epoch_num = epoch)\n",
        "\n",
        "        epoch_losses.append(loss)\n",
        "    return epoch_losses"
      ],
      "metadata": {
        "id": "V36dKfOgc5A_"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(model, criterion, optimizer, loader, epoch_num):\n",
        "    running_loss = 0.0\n",
        "    for x, y in tqdm(loader):\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(x)\n",
        "\n",
        "        losses = [criterion(output, y) for output in outputs]\n",
        "        total_loss = sum(losses)\n",
        "\n",
        "        total_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += total_loss.item()\n",
        "\n",
        "\n",
        "    avg_loss = running_loss / len(loader)\n",
        "    print(f\"Epoch {epoch_num + 1} — Avg Loss: {avg_loss:.4f}\")\n",
        "    torch.save(model.state_dict(), 'model_last.pth')\n",
        "    return avg_loss"
      ],
      "metadata": {
        "id": "1nC4BzMHf0l0"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_stat = train(model, criterion, optimizer, loader, 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CBsD9I4thGUa",
        "outputId": "748f4acf-5777-48d0-f41c-10e302c22b32"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/1 [00:00<?, ?it/s]\n",
            "  0%|          | 0/25325 [00:00<?, ?it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "res1  torch.Size([8, 5, 128, 128])\n",
            "skip1  torch.Size([8, 128, 128, 128]) merge1  torch.Size([8, 128, 128, 128])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/25325 [00:08<?, ?it/s]\n",
            "100%|██████████| 1/1 [00:08<00:00,  8.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 — Avg Loss: 2.0617\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V1StzgdxthVl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
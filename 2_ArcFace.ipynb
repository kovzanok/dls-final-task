{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kovzanok/dls-final-task/blob/main/2_ArcFace.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ArcFace Loss (Additive Angular Margin Loss)"
      ],
      "metadata": {
        "id": "f-tZoxywJ1I0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Теория ArcFace"
      ],
      "metadata": {
        "id": "yKGDNGvnrrNC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "В случае с обучением на задачу классификации первая подходящая лосс-функция, которая нам приходит в голову — Cross-Entropy. И на ней действительно можно обучать сеть для распознавания лиц. Но за много лет люди придумали более хитрые лосс-функции, которые делают обучение сети для распознавания лиц более эффективным. Одним из лучших считается ArcFace Loss (Additive Angular Margin Loss).\n",
        "\n",
        "Этот лосс — чуть измененная кросс-энтропия. Он позволяет достичь лучшего распределения векторов лиц на сфере. В нем добавлены некоторые дополнительные ограничения и гиперпараметры, для того чтобы эмбеддинги лиц одного класса были более близки между собой, а эмбеддинги лиц разных людей оставались далеки. То есть, этот лосс позволяет лучше кластеризовать лица на сфере единичного радиуса.\n"
      ],
      "metadata": {
        "id": "R70bm-ayJznN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Как устроен ArcFace**:\n",
        "\n",
        "Стандартные SoftMax + кросс-энтропия (CE) выглядят так:\n",
        "\n",
        "$$L_{CE} = \\frac{-1}{N}\\sum_1^N \\frac{e^{W_{y_i}^{T}x_i + b_{y_i}}}{\\sum^n_{j=1}e^{W_j^Tx_i+b_j}},$$\n",
        "\n",
        "здесь:\n",
        "- $x_i \\in \\mathbb{R^d}$ — вектор $i$-го элемента обучающей выборки перед последним полносвязным слоем сети. $y_i$ — класс этого элемента;\n",
        "- $W_j \\in \\mathbb{R^d}$ — j-ый столбец матрицы весов последнего слоя сети (т.е. слоя, который производит итоговую классификацю входящего объекта);\n",
        "- $b_j \\in \\mathbb{R^d}$ — j-ый элемент вектора байеса последнего слоя сети;\n",
        "- $N$ — batch size;\n",
        "- $n$ — количество классов.\n",
        "\n",
        "\n",
        "Хотя этот лосс работает хорошо, он явным образом не заставляет эмбеддинги $x_i$ элементов, принадлежащих одному классу, быть близкими друг к другу по расстоянию. И не заставляет эмбеддинги элементов, принадлежащих разным классам, быть далеко друг от друга. Все, что хочет этот лосс — чтобы на основе эмбеддингов $x_i$ можно было хорошо классифицировать элементы, никакие ограничений на расстояния между эмбеддингами $x_i$ он не вводит.\n",
        "\n",
        "Из-за этого у нейросетей для распознавания лиц, которые обучены на обычном CE loss, бывают проблемы с распознаванием лиц, которые сильно отличаются от лиц того же человека разными допатрибутами (шляпа/прическа/очки и т.п.). Просто эмбеддинг для таких лиц получается довольно далек по расстоянию от других эмбеддингов лиц этого же человека.\n",
        "\n",
        "Давайте теперь немного поправим формулу:\n",
        "- уберем байес последнего слоя, т.е. сделаем $b_j=0$;\n",
        "- нормализуем веса последнего слоя: ||$W_j$|| = 1;\n",
        "- нормализуем эмбеддинги: ||$x_i$|| = 1. Перед подачей их на вход последнему слою (т.е. перед умножением на матрицу $W_j$) умножим их на гиперпараметр s. По сути, мы приводим норму всех эмбеддингов к s. Смысл этого гиперпараметра в том, что, возможно, сети проще будет классифицировать эмбеддинги, у которых не единичная норма.\n",
        "\n",
        "Нормализация эмбеддингов приводит к тому, что эмбеддинги начинают быть распределены по сфере единичного радиуса (и сфере радиуса s после умножения на ниперпараметр s). И итоговые предсказания сети после последнего слоя зависят только от угла между эмбеддингами $x_i$ и выученных весов $W_j$. От нормы эмбеддинга $x_i$ они больше не зависят, т.к. у всех эмбеддингов они теперь одинаковые.\n",
        "\n",
        "Получается, в степени экспоненты у нас останется выражение $s W_{y_i}^{T}x_i$, которое можно переписать в виде  $s W_{y_i}^{T}x_i = s ||W_{y_i}||\\cdot ||x_i|| \\cdot cos\\Theta_{y_i}$. Тут $\\Theta_{y_i}$ — это угод между векторами $W_{y_i}$ и $x_i$. Но так как мы сделали нормы $W_{y_i}$ и $x_i$ единичными, то все это выражение просто будет равно $s cos\\Theta_{y_i}$.\n",
        "\n",
        "В итоге мы получим следующую формулу лосса:\n",
        "\n",
        "$$L = \\frac{-1}{N}\\sum_1^N \\frac{e^{s\\ cos\\Theta_{y_i}}}{e^{s\\ cos\\Theta_{y_i}} + \\sum^n_{j=1,\\ j\\ne y_i} e^{s\\ cos\\Theta_j}}$$\n",
        "\n",
        "\n",
        "И последний шаг. Добавим еще один гиперпараметр $m$. Он называется additive angular margin penalty и заставляет эмбеддинги одного класса быть ближе друг к другу, а эмбеддинги разных классов — более далекими друг от друга.\n",
        "\n",
        "В итоге получим вот что:\n",
        "\n",
        "$$L_{ArcFace} = \\frac{-1}{N}\\sum_1^N \\frac{e^{s\\ cos(\\Theta_{y_i} + m)}}{e^{s\\ cos(\\Theta_{y_i} + m)} + \\sum^n_{j=1,\\ j\\ne y_i} e^{s\\ cos\\Theta_j}}$$\n",
        "\n",
        "Это и есть ArcFace Loss с двумя  гиперпараметрами, s и m.\n",
        "\n",
        "Получается, что ArcFace Loss завтавляет сеть выучивать эмбеддинги, распределенные по сфере радиуса s, причем чтобы эмбеддинги одного класса были ближе друг к другу, а эмбеддинги разных классов — более далеки друг от друга.\n",
        "\n"
      ],
      "metadata": {
        "id": "r5N_BHHSK1JR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Доплитература по ArcFace Loss:**\n",
        "\n",
        "Оригинальная статья: https://arxiv.org/pdf/1801.07698.pdf"
      ],
      "metadata": {
        "id": "EI80vHxcRo4u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Другие лоссы"
      ],
      "metadata": {
        "id": "BSnVw2zNrjpn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Кроме ArcFace, есть еще много разных вариантов лоссов для задачи face recognition. Некоторые из них можно найти, например, [тут](https://openaccess.thecvf.com/content_CVPRW_2020/papers/w48/Hsu_A_Comprehensive_Study_on_Loss_Functions_for_Cross-Factor_Face_Recognition_CVPRW_2020_paper.pdf). Вы можете попробовать реализовать другие лосс-функции в этом проекте в качестве дополнительного задания.\n",
        "\n",
        "Кроме этого, можно миксовать лосс-функции. Например, обучать нейросеть на сумме ArcFace и TripletLoss. Часто так выходит лучше, чем если обучать на каком-то одном лоссе."
      ],
      "metadata": {
        "id": "rdnYR55ZXOzx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Датасет"
      ],
      "metadata": {
        "id": "pT4nsFZyivfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "В качестве датасета нужно использовать картинки из CelebA, выровненные при помощи своей модели из задания 1. Очень желательно их еще кропнуть таким образом, чтобы нейросети поступали на вход преимущественно только лица без какого либо фона, частей тела и прочего. Целиком брать весь датасет CelebA не обязательно, он слишком большой.\n",
        "\n",
        "Если планируете делать дополнительное задание на Identificaton rate metric, то **обязательно разбейте заранее датасет на train/val или train/val/test.** Это нужно сделать не только на уровне кода, а на уровне папок, чтобы точно знать, на каких картинках модель обучалась, а на каких нет. Лучше заранее почитайте [ноутбук с заданием](https://colab.research.google.com/drive/1sjO2-N8EsLb2HQcOELikFQCqKUWrPehJ?usp=sharing)."
      ],
      "metadata": {
        "id": "loDtEBkUizfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# План заданий"
      ],
      "metadata": {
        "id": "qhF-n904jYJz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Итак, вот, что от вас требуется в этом задании:\n",
        "\n",
        "* Выбрать модель (или несколько моделей) для обучения. Можно брать предобученные на ImageNet, но нельзя использовать модели, предобученные на задачу распознавания лиц.\n",
        "* Обучить эту модель (модели) на CE loss. Добиться accuracy > 0.7.\n",
        "* Реализовать ArcFace loss.\n",
        "* Обучить модель (модели) на ArcFace loss. Добиться accuracy > 0.7.\n",
        "* Написать небольшой отчет по обучению, сравнить CE loss и ArcFace loss.\n",
        "\n",
        "**P.S. Не забывайте сохранять модели после обучения**"
      ],
      "metadata": {
        "id": "dqmhb66-jhaK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Зависимости и загрузка данных"
      ],
      "metadata": {
        "id": "c3ucZ7mFjQsn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DG4RhSxaTWcs",
        "outputId": "e821a7e9-7093-42e4-9da2-31f1a702db69"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "from torch.optim import Adam\n",
        "from torch.utils.data import Dataset, DataLoader, random_split, Subset\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.utils as vutils\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm.auto import tqdm\n",
        "import torchvision.transforms.functional as TF\n",
        "import cv2\n",
        "\n",
        "import random\n",
        "import os"
      ],
      "metadata": {
        "id": "eHNy9XnXgGHu"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "JXgqmonjkSxD"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "random.seed(42)"
      ],
      "metadata": {
        "id": "ycXe2lYulvWx"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Датасет"
      ],
      "metadata": {
        "id": "Qh5FGacSzDwu"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aY7OM8SszFm2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}